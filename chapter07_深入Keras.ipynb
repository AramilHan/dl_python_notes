{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68314ea5-71df-4cc5-ae2e-d6080e66d5a3",
   "metadata": {},
   "source": [
    "# 本章摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3cd07-997a-4290-81ba-b7ea46f30fc3",
   "metadata": {},
   "source": [
    "**本章包括以下内容：**\n",
    "- 构建Keras模型的3种方法，即序贯模型、函数式API和模型子类化\n",
    "- 使用Keras内置的训练循环和评估循环\n",
    "- 使用Keras回调函数来自定义训练\n",
    "- 使用TensorBoard监控训练指标和评估指标\n",
    "- 从头开始编写训练循环和评估循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33396515-70bd-4263-86d3-311cc3522548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Keras工作流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018ca0d-f2db-4f05-accc-6896d97b78dc",
   "metadata": {},
   "source": [
    "Keras API的设计原则是**渐进式呈现复杂性**。<p>\n",
    "Keras 提供了**一系列工作流程**。既有非常简单的工作流程，也有非常灵活的工作流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb3d356-8f96-439d-a4b2-c2c877bfa90e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 构建Keras模型的不同方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1da284-0f44-403d-bce1-5a88a71bbae0",
   "metadata": {},
   "source": [
    "在Keras中，构建模型可以使用以下3个API：\n",
    "- **序贯模型**（sequential model）：这是最容易理解的API。它本质上是Python列表，仅限于层的简单堆叠。\n",
    "- **函数式API**（functional API）：专注于类似图的模型结构。它在可用性和灵活性之间找到了很好的平衡点，因此是构建模型最常用的API。\n",
    "- **模型子类化**（model subclassing）：是一个底层选项，可以从头开始自己编写所有内容。<p>\n",
    "\n",
    "![Keras渐进式呈现复杂性](images/Keras渐进式呈现复杂性.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855d482-fd88-41dc-94ad-75f413f966fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 序贯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a8e7955-9394-4a16-860f-3c5c8f95f4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_11/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.01615956, -0.06874424,  0.00115848, -0.01091331, -0.04483801,\n",
       "         -0.04789981,  0.03007901, -0.06900203, -0.1380572 ,  0.12745562,\n",
       "         -0.23870517, -0.14678456, -0.1876929 , -0.25432742, -0.14858615,\n",
       "          0.24506742,  0.2848544 ,  0.2833345 ,  0.01095375,  0.21575624,\n",
       "          0.11743551,  0.2803548 ,  0.02765855,  0.29020333,  0.04580933,\n",
       "          0.10731539,  0.2661476 ,  0.14312902, -0.1966697 , -0.2872001 ,\n",
       "          0.12172163, -0.03410977,  0.13054127,  0.0606257 , -0.18438274,\n",
       "         -0.10214819, -0.07672796, -0.01987404,  0.07959318,  0.16681272,\n",
       "          0.03780529,  0.14951974, -0.08676931, -0.15649359,  0.07808846,\n",
       "         -0.15318507, -0.14740764, -0.10751787,  0.04491299, -0.26342505,\n",
       "          0.00499746,  0.2355125 , -0.16051902,  0.04607168, -0.04732111,\n",
       "         -0.08319381, -0.15369698, -0.189175  , -0.2719413 , -0.23080415,\n",
       "          0.08646289,  0.261347  , -0.25805488, -0.19228318],\n",
       "        [-0.05141746, -0.1469057 , -0.28843382, -0.20429958,  0.12459344,\n",
       "          0.28792524,  0.02224335, -0.16601647, -0.28909144,  0.15191987,\n",
       "         -0.21450448, -0.27700526, -0.13896003, -0.16960226, -0.04348662,\n",
       "          0.0679757 , -0.10831667,  0.11621484, -0.00757903,  0.04177228,\n",
       "         -0.05678956, -0.2804696 , -0.13816594, -0.11855088, -0.07543892,\n",
       "         -0.06563863,  0.09817269,  0.13981414,  0.00456816, -0.25703424,\n",
       "         -0.02871785,  0.24087083, -0.10055472, -0.08450967,  0.20836669,\n",
       "          0.16927871,  0.21130663,  0.22696358,  0.16237426, -0.06789057,\n",
       "         -0.2593121 ,  0.00916344, -0.07843901, -0.05007127,  0.03826442,\n",
       "         -0.26713192, -0.06998284,  0.1964047 , -0.24961975, -0.14320798,\n",
       "          0.22736335,  0.25772578,  0.13501689,  0.0091939 , -0.12203863,\n",
       "         -0.2750094 ,  0.25891715,  0.18873173, -0.07200626,  0.11332712,\n",
       "          0.2740001 ,  0.14031199,  0.10746798,  0.0314458 ],\n",
       "        [-0.06490968,  0.28290153, -0.05871965,  0.1899193 , -0.17342891,\n",
       "         -0.2783438 , -0.22330883, -0.17820919, -0.25864685, -0.26420915,\n",
       "          0.20155662,  0.03939235, -0.2845693 , -0.17769034,  0.07405114,\n",
       "          0.25671434,  0.29691398, -0.13156666,  0.13934922, -0.04024166,\n",
       "         -0.29570714,  0.10229859,  0.11585239,  0.18756363, -0.29316667,\n",
       "         -0.06603882,  0.1975193 ,  0.05545408, -0.14711654,  0.04653278,\n",
       "         -0.18027177, -0.12140043,  0.10631236,  0.10102361,  0.2670455 ,\n",
       "          0.29238576,  0.28564566, -0.2516421 ,  0.00677171,  0.2693761 ,\n",
       "          0.20310771,  0.29233932, -0.2126503 , -0.13038564, -0.02508292,\n",
       "          0.29402083, -0.01331627,  0.07719064,  0.24645138, -0.27670318,\n",
       "         -0.13302079,  0.2767728 , -0.19344828,  0.05339935, -0.07236898,\n",
       "         -0.11950858, -0.13746966,  0.2211631 , -0.07952449, -0.05812882,\n",
       "         -0.2191036 , -0.21533197, -0.27323788, -0.0795608 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_11/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_12/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.20496741,  0.2770699 ,  0.24749902,  0.2578915 ,  0.16828424,\n",
       "         -0.02291203, -0.21913275,  0.01399913,  0.19080555, -0.05503258],\n",
       "        [ 0.1718412 ,  0.12919909,  0.17096755, -0.19908443, -0.28323135,\n",
       "         -0.10316892, -0.12942033, -0.12959547, -0.27863106,  0.17736956],\n",
       "        [ 0.12433028,  0.06753394, -0.211454  ,  0.01526424, -0.21484819,\n",
       "          0.03513008, -0.20915495,  0.06431648,  0.0620614 ,  0.19196334],\n",
       "        [ 0.1204443 ,  0.1043753 ,  0.1582717 ,  0.2575253 ,  0.16202235,\n",
       "          0.18622372,  0.03327978,  0.11960533,  0.11823663,  0.12402552],\n",
       "        [ 0.11039868,  0.03653431,  0.17610723,  0.08360037, -0.14300025,\n",
       "          0.2804608 ,  0.10186863, -0.12747382, -0.03385833,  0.23978719],\n",
       "        [-0.03170183,  0.23327383, -0.27684715,  0.11472505, -0.19719031,\n",
       "          0.02998754, -0.02852842,  0.0429697 ,  0.17749473,  0.2720218 ],\n",
       "        [ 0.2797415 , -0.06598648, -0.0271157 ,  0.11427251, -0.05458614,\n",
       "         -0.13273677, -0.17287965, -0.1569877 , -0.16931221,  0.01281434],\n",
       "        [ 0.02655169,  0.0817571 , -0.01211032, -0.17493546, -0.0693806 ,\n",
       "          0.11184603,  0.16263884, -0.06428674, -0.21058401,  0.12041232],\n",
       "        [ 0.01089749, -0.27738932,  0.0606901 ,  0.06538153, -0.02296504,\n",
       "          0.177445  ,  0.03158253,  0.1331661 , -0.01979902, -0.25158244],\n",
       "        [-0.13462694,  0.15237626, -0.15167178, -0.2190468 ,  0.14018232,\n",
       "          0.03275993,  0.2127412 ,  0.16278955, -0.12145062, -0.25526637],\n",
       "        [-0.07120776, -0.07551165,  0.24952736, -0.2689557 , -0.00750446,\n",
       "         -0.1282297 , -0.08546942,  0.13119507,  0.03900769,  0.2302812 ],\n",
       "        [ 0.09291154,  0.15917563, -0.27338576, -0.04602654,  0.06202847,\n",
       "          0.25638327,  0.20552784,  0.24750587,  0.25457278,  0.16800317],\n",
       "        [ 0.03629506, -0.22678602, -0.09073795, -0.17644593, -0.16827555,\n",
       "         -0.11703953,  0.18884146, -0.0902801 ,  0.09168962, -0.19433048],\n",
       "        [-0.11977947, -0.00262961, -0.11680877, -0.2770557 , -0.23846436,\n",
       "          0.07261163,  0.00693813,  0.1888777 ,  0.2175338 ,  0.0901171 ],\n",
       "        [ 0.28293476,  0.111467  ,  0.25204477,  0.20324942,  0.17959529,\n",
       "          0.19361061, -0.07454063, -0.04189719, -0.17977996, -0.18783826],\n",
       "        [ 0.21585074,  0.24170241, -0.12584026, -0.0167838 ,  0.10767388,\n",
       "          0.26671538, -0.09197822,  0.2023369 , -0.05393665,  0.17250863],\n",
       "        [-0.0178299 ,  0.03242564, -0.08786766, -0.22789614,  0.0394665 ,\n",
       "          0.02913854,  0.12434092, -0.1733713 ,  0.2823476 ,  0.15495184],\n",
       "        [ 0.2728106 ,  0.21812913, -0.16123918, -0.08605516, -0.1833345 ,\n",
       "          0.20914245,  0.26319167,  0.25684097, -0.04351649,  0.2813473 ],\n",
       "        [ 0.26365831,  0.08316845,  0.04538012, -0.08730759, -0.17617762,\n",
       "         -0.15389434,  0.06770399, -0.26739243,  0.11551502,  0.04888651],\n",
       "        [-0.17946109, -0.10599038, -0.07065473,  0.10764652,  0.08517769,\n",
       "          0.05350655,  0.21897706, -0.16724283, -0.2298956 , -0.03914748],\n",
       "        [-0.16230592, -0.27851647, -0.03718068,  0.07799375, -0.20257133,\n",
       "         -0.02277461,  0.0696907 ,  0.10354882, -0.07780121,  0.1523726 ],\n",
       "        [ 0.2448453 ,  0.00242913,  0.26003698, -0.2079787 , -0.17324543,\n",
       "          0.08247069,  0.08888885, -0.19696805,  0.1421957 , -0.27390552],\n",
       "        [ 0.07783794, -0.2717672 ,  0.24163565, -0.25293845, -0.16218536,\n",
       "         -0.14673088,  0.01389867,  0.03414509, -0.16508782,  0.09959516],\n",
       "        [-0.17236403, -0.21157384,  0.12764788,  0.257126  , -0.04298343,\n",
       "          0.25307325, -0.2572122 , -0.21779233,  0.07424104,  0.12225395],\n",
       "        [-0.27333122, -0.02929685,  0.24172279, -0.20034532, -0.23596984,\n",
       "         -0.16460302, -0.26115322, -0.15576482, -0.2710848 ,  0.07309717],\n",
       "        [-0.12477705, -0.18081948, -0.24928853,  0.08682632,  0.22695366,\n",
       "         -0.03759527,  0.00940645, -0.04233699, -0.26048404,  0.1321972 ],\n",
       "        [-0.11860207,  0.25078872,  0.1062988 ,  0.1229797 , -0.01573771,\n",
       "          0.18804055, -0.11962387,  0.21809193,  0.03635588,  0.19521129],\n",
       "        [ 0.18556887, -0.241499  , -0.27996337,  0.12580475, -0.07713054,\n",
       "         -0.06332149,  0.24232408, -0.09381095,  0.14898622,  0.10389444],\n",
       "        [-0.09151392, -0.25838104, -0.06394282,  0.18647051, -0.03289402,\n",
       "          0.06542015, -0.21295342,  0.26390722, -0.14459564,  0.09774411],\n",
       "        [ 0.05892777, -0.2191897 ,  0.19263849, -0.14507331,  0.14190418,\n",
       "          0.28466478,  0.20768157, -0.18637158, -0.25579622,  0.2835609 ],\n",
       "        [-0.1667634 , -0.06538695,  0.03474882,  0.17116144,  0.14665782,\n",
       "          0.1836766 , -0.07024163, -0.04671094,  0.255668  ,  0.24702546],\n",
       "        [-0.28229028, -0.10976835, -0.04793878,  0.05530819, -0.02397883,\n",
       "         -0.2748341 , -0.17792735, -0.2305187 ,  0.17062974, -0.02035028],\n",
       "        [ 0.16139147,  0.06337351, -0.10337897,  0.24285612,  0.16379392,\n",
       "         -0.15345754,  0.03016195, -0.21176521,  0.08830896,  0.18710762],\n",
       "        [ 0.06922647,  0.07492489,  0.0807091 ,  0.02657735, -0.04005747,\n",
       "         -0.01085052, -0.2739343 , -0.210483  , -0.18516289,  0.18452662],\n",
       "        [-0.15073906,  0.11441398, -0.08463894,  0.2278969 , -0.11063196,\n",
       "          0.17643431,  0.08428508,  0.06037247,  0.13455322, -0.03867301],\n",
       "        [-0.2803075 ,  0.02930066,  0.1701732 , -0.11668964, -0.26390788,\n",
       "         -0.09291129,  0.16451225,  0.07372385, -0.26662704, -0.15818268],\n",
       "        [-0.2070326 , -0.11526498,  0.1314449 ,  0.00289553,  0.26398823,\n",
       "         -0.04609355,  0.17685354, -0.1574604 , -0.2717784 , -0.03043652],\n",
       "        [ 0.23849192,  0.1548549 ,  0.1045523 , -0.11637558,  0.2823631 ,\n",
       "          0.22148666, -0.1556272 ,  0.05304894, -0.21836784,  0.15830746],\n",
       "        [ 0.01525792, -0.05181123, -0.2063922 , -0.17746833, -0.27185723,\n",
       "          0.28217772, -0.23126873, -0.0474142 ,  0.24522439,  0.1965299 ],\n",
       "        [-0.17662406, -0.05536638, -0.16783664,  0.00889382, -0.12628222,\n",
       "         -0.16599324,  0.06886241, -0.08576739,  0.08380723, -0.25706547],\n",
       "        [-0.15010138, -0.10186911, -0.01582414, -0.13404493, -0.12310338,\n",
       "         -0.17667744, -0.27707198, -0.26415575,  0.11875904, -0.10356694],\n",
       "        [ 0.23013332,  0.2496281 ,  0.11432695,  0.12741551,  0.06434906,\n",
       "         -0.08048487,  0.08447397,  0.07940584, -0.2558815 , -0.2129198 ],\n",
       "        [ 0.06362006, -0.05170506,  0.10450131,  0.06981564, -0.05766925,\n",
       "         -0.25848323, -0.06553577, -0.13882338, -0.13097526, -0.07152677],\n",
       "        [-0.12103921, -0.04341811,  0.18260333,  0.20706409, -0.0094218 ,\n",
       "         -0.13595091, -0.1752902 , -0.06588511,  0.07663509,  0.12433469],\n",
       "        [ 0.02510083,  0.11226842, -0.2350746 , -0.026777  , -0.11500707,\n",
       "          0.2751356 , -0.27422187,  0.16401726, -0.10760784,  0.09939557],\n",
       "        [ 0.11660531,  0.21463454, -0.23895308,  0.15838066,  0.02635249,\n",
       "          0.07676163,  0.22116569, -0.05157702,  0.25289896, -0.18460362],\n",
       "        [ 0.03374079, -0.22814794, -0.06094483, -0.15055473,  0.12205932,\n",
       "         -0.24582265, -0.05430175,  0.19090202,  0.10481876, -0.15337607],\n",
       "        [ 0.0133068 ,  0.13776234,  0.16551435,  0.01410314,  0.17750847,\n",
       "          0.00271142, -0.20393264,  0.08851567,  0.01053131,  0.12764895],\n",
       "        [-0.15352216, -0.04618303,  0.03016943,  0.14742953, -0.16431354,\n",
       "         -0.1599844 , -0.21377629,  0.01428881, -0.12157269,  0.2662492 ],\n",
       "        [ 0.173336  , -0.08651009,  0.01151705,  0.07126486,  0.07279336,\n",
       "         -0.03540374, -0.01437137,  0.2581704 ,  0.2088092 , -0.18902671],\n",
       "        [ 0.2652184 ,  0.2740014 ,  0.14540717,  0.17116499, -0.22835377,\n",
       "          0.13996342,  0.02815366, -0.15382434,  0.16587165, -0.14679606],\n",
       "        [ 0.17788687,  0.16343275,  0.02486342, -0.00157395,  0.02349329,\n",
       "          0.17902136,  0.10623458,  0.03238484,  0.2106111 ,  0.16111684],\n",
       "        [-0.03390121,  0.2760817 , -0.17876318, -0.03765684,  0.24401203,\n",
       "         -0.1627007 ,  0.20530578, -0.11673872,  0.21202108,  0.20404181],\n",
       "        [-0.20856085, -0.00631815, -0.1137203 ,  0.10140556,  0.25166026,\n",
       "          0.14272487,  0.24942991, -0.2584306 , -0.06455259, -0.24511483],\n",
       "        [-0.23469305,  0.08087015, -0.2312914 ,  0.00907433,  0.12322307,\n",
       "         -0.1611172 , -0.22077471, -0.16002622,  0.07543635,  0.14210778],\n",
       "        [ 0.14515159, -0.14136153,  0.09419078,  0.08773446, -0.25451443,\n",
       "         -0.02835318, -0.24200967,  0.27451804, -0.1154846 , -0.02123564],\n",
       "        [ 0.19258615, -0.04180725, -0.27301446, -0.08051616,  0.22931978,\n",
       "          0.17544308, -0.05121653, -0.10220245,  0.12428817,  0.15272856],\n",
       "        [ 0.05941007, -0.19784714, -0.20734972, -0.04435077, -0.07845607,\n",
       "          0.27486947, -0.18761382,  0.2701269 , -0.05101931,  0.15528518],\n",
       "        [ 0.24948987,  0.21962318,  0.1574421 ,  0.00848171, -0.18069619,\n",
       "         -0.22960816, -0.23046091,  0.16903874, -0.25693133,  0.08206743],\n",
       "        [ 0.00617221, -0.14612077, -0.27627456,  0.19137031,  0.17958736,\n",
       "          0.02533659,  0.27738222,  0.27834478, -0.19121704, -0.00928125],\n",
       "        [-0.05698833,  0.05754107,  0.21544859,  0.12376237, -0.1730834 ,\n",
       "          0.15052229,  0.13788262,  0.14336991, -0.16209066, -0.26127008],\n",
       "        [ 0.25966015,  0.27294436,  0.04071966, -0.12527984, -0.11681557,\n",
       "          0.0767636 , -0.00326696, -0.02416837,  0.18578821, -0.19910975],\n",
       "        [ 0.13757712,  0.2249997 , -0.10708347,  0.11335817,  0.01846683,\n",
       "         -0.27663988,  0.13214669, -0.23959254,  0.09928647,  0.00398809],\n",
       "        [-0.15924324, -0.09461944, -0.06455714,  0.18833596,  0.21328491,\n",
       "          0.00722605, -0.16691132, -0.00244135, -0.15304308, -0.19239253]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_12/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Sequential类构建模型\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "# 使用add()方法\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "# 只有在数据上调用模型或者调用模型的build()方法并给定输入形状时，模型才有权重\n",
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf93c1a-4870-495a-b349-df756fb85bab",
   "metadata": {},
   "source": [
    "### 使用summary()方法显示模型内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f081a3-e931-4c42-8efa-c0fb38b32490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e715b7a6-9b60-4b00-baa3-b00bf4569c2b",
   "metadata": {},
   "source": [
    "### 使用name参数命名模型和层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6f1c83-45a8-41da-acb1-19f01f367a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name='my_example_model')\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build(input_shape=(None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5d352-65ca-47d0-b181-a99dd37d99cc",
   "metadata": {},
   "source": [
    "### 提前声明模型的输入形状，随时查看模型变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adffac62-9ca6-46f9-9544-1b58c9feb688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a722b-5bc0-470b-96cc-143cfa7d7fbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 函数式API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76889597-b559-4e4e-93b6-7f4a1ffa2f60",
   "metadata": {},
   "source": [
    "序贯模型易于使用，但使用范围非常有限：**它只能表示具有单一输入和单一输出的模型，按顺序逐层进行处理。** 想要使用其他类型的模型，就可以使用函数式API构建模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ba9e9-a7cb-4a83-9161-a7d87811be4e",
   "metadata": {},
   "source": [
    "### 简单示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65bda227-88a3-464f-8cea-32d49a0bb181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 首先声明一个Input：Input对象保存了关于模型将处理的数据形状和数据类型的信息。Input对象叫作符号张量\n",
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "# 接下来，创建一个层，并在输入上调用Input层\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "# 得到最终输出之后，在Model构造函数中指定输入和输出，将模型实例化\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "# 查看模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40748f3-80fa-40f9-96a3-ae99572c2e47",
   "metadata": {},
   "source": [
    "### 多输入、多输出模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8181c84-6fb8-48ef-9adf-00d6a7438220",
   "metadata": {},
   "source": [
    "假设要构建一个系统，按优先级对客户支持工单进行排序，并将工单转给相应的部分。这个模型有3个输入：\n",
    "- 工单标题（文本输入）\n",
    "- 工单文本正文（文本输入）\n",
    "- 用户添加的标签（分类输入，假定为one-hot编码） <p>\n",
    "\n",
    "将文本输入编码为1和0组成的数组，数组大小为vocabulary_size。 <p>\n",
    "模型还有2个输出：\n",
    "- 工单的优先级分数，它是介于0和1之间的标量（sigmoid输出）\n",
    "- 应处理工单的部分（对所有部分做softmax）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74536a80-d363-4fcd-97dc-836e5cdfd85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 21:00:17.450414: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "# 定义模型输入，有三个输入需要定义三个Input对象\n",
    "title_input = keras.Input(shape=(vocabulary_size, ), name=\"title\")\n",
    "text_body_input = keras.Input(shape=(vocabulary_size, ), name=\"text_body\")\n",
    "tags_input = keras.Input(shape=(num_tags, ), name=\"tags\")\n",
    "# 通过拼接将输入特征组合成张量features\n",
    "features = layers.Concatenate()([title_input, text_body_input, tags_input])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "model = keras.Model(inputs=[title_input, text_body_input, tags_input], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd4c10-a0fd-4b62-a9e5-1b8b3a70bc30",
   "metadata": {},
   "source": [
    "### 训练一个多输入、多输出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1291179f-dbc8-4228-815f-2a8704b766dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 5ms/step - loss: 33.2137 - priority_loss: 0.3356 - department_loss: 32.8781 - priority_mean_absolute_error: 0.5043 - department_accuracy: 0.2992\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.5738 - priority_loss: 0.3385 - department_loss: 30.2352 - priority_mean_absolute_error: 0.5074 - department_accuracy: 0.5711\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "# 虚构输入数据\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "# 虚构目标数据\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "\n",
    "model.fit(\n",
    "    [title_data, text_body_data, tags_data],\n",
    "    [priority_data, department_data],\n",
    "    epochs=1)\n",
    "\n",
    "model.evaluate(\n",
    "    [title_data, text_body_data, tags_data],\n",
    "    [priority_data, department_data])\n",
    "\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521259ff-406d-4e55-a811-60d96bd78224",
   "metadata": {},
   "source": [
    "#### 通过给定输入和目标组成的字典来训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a6e91b-7a2a-4e04-9f53-77277b726c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 7ms/step - loss: 38.3720 - priority_loss: 0.3385 - department_loss: 38.0335 - priority_mean_absolute_error: 0.5074 - department_accuracy: 0.2703\n",
      "40/40 [==============================] - 0s 975us/step - loss: 0.0000e+00 - priority_loss: 0.0000e+00 - department_loss: 0.0000e+00 - priority_mean_absolute_error: 0.0000e+00 - department_accuracy: 0.0000e+00\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "    metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_data, \"department\": department_data},\n",
    "    epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a3916-130b-4946-810c-2bb94c832519",
   "metadata": {},
   "source": [
    "### 获取层的连接方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f606ce-6274-4933-a7f6-b6b3452fde9c",
   "metadata": {},
   "source": [
    "函数式模型是一种图数据结构。这便于查看层与层之间是如何连接的，并重复使用之前的图节点（层输出）作为新模型的一部分。<p>\n",
    "**思考深度神经网络时使用的“思维模式”：** 由层构成的图。 <p>\n",
    "两个重要的用处：\n",
    "- 模型可视化\n",
    "- 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49554b35-4003-4331-bc65-57c11b679fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "# 可视化上述模型的连接方式（模型的拓扑结构）\n",
    "keras.utils.plot_model(model, to_file=\"ticker_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb76e44-b0b0-4a26-832d-f1338f5d4279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# 将模型每一层的输入形状和输出形状添加到这张图中\n",
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f047ff-c8c1-4ea5-b1ce-81dc03a1bd75",
   "metadata": {},
   "source": [
    "#### 检索函数式模型某一层的输入或输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218dcad8-e761-455d-93fb-6f8431061acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fa02a310940>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7fa02a312590>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7fa02a382fb0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x7fa030415810>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa02a3543a0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa02a180040>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa02a180370>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检索函数式模型某一层的输入或输出\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f519f604-e522-46fa-af01-7d098a0ef0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6dd1e49-23d5-4ed8-94b6-e59700665e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb7169-5b5b-4c91-885d-8111723780c7",
   "metadata": {},
   "source": [
    "#### 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d08fe-1b2e-4bdd-9228-a512ef75e6bd",
   "metadata": {},
   "source": [
    "特征提取，重复使用模型的中间特征来创建新模型。<p>\n",
    "假设，对前一个模型增加一个输出 —— 估算某个问题工单的解决时长，这是一种难度评分。实现方法是利用包含3个类别的分类层，这3个类别分别是 “快速”，“中等”，“困难”。无须从头开始重新创建和训练模型。可以从前一个模型的中间特征开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd771b6-cbe6-4ca9-8429-2b2770058b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "new_model = keras.Model(inputs=[title_input, text_body_input, tags_input], outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd0736d-a6b1-484c-b5d9-67fd4842c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d5901-4e30-457d-82db-5e6cb8e8ea37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 模型子类化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d70ef-92ed-409d-9fc1-3245d36a4966",
   "metadata": {},
   "source": [
    "构建模型的最高级方法：**模型子类化**，也就是将Model类子类化：<p>\n",
    "- 在`__init__()`方法中，定义模型将使用的层；\n",
    "- 在`call()`方法中，定义模型的前向传播，重复使用之前创建的层；\n",
    "- 将子类实例化，并在数据上调用，从而创建权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc912c7-90af-4d60-867f-7eb63fbf9b56",
   "metadata": {},
   "source": [
    "### 将前一个例子重新实现为Model子类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc12ecb-e35e-490e-9ee9-e7017f4bc5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "    def __init__(self, num_departments):\n",
    "        # 调用super()构造函数\n",
    "        super().__init__()\n",
    "        # 在构造函数中定义子层\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(num_departments, activation=\"softmax\")\n",
    "\n",
    "    # 在call()方法中定义前向传播\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f671c48-256d-4402-acce-e2c81d3fb157",
   "metadata": {},
   "source": [
    "#### 将Model子类实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676f04b0-bcae-4ee1-944a-576535feabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "priority, department = model({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739dcc8-76db-453c-a64c-38e1e0498ddb",
   "metadata": {},
   "source": [
    "### Layer子类与Model子类之间的区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a44fe-45cc-47ff-80cb-01482e02b78e",
   "metadata": {},
   "source": [
    "- “层”（layer）是用来创建模型的组件；\n",
    "- “模型”（model）是高阶对象，用于训练、导出进行推理等；\n",
    "- 总结：Model有`fit()`、`evaluate()`和`predict()`等方法，而Layer没有。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36ee31-046a-446a-90f9-08d0fbf42c57",
   "metadata": {},
   "source": [
    "### 编译和训练Model子类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b6fa5e-b019-4962-b740-ddaa234d4116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 65.6191 - output_1_loss: 0.3141 - output_2_loss: 65.3050 - output_1_mean_absolute_error: 0.4837 - output_2_accuracy: 0.1211\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 37.4825 - output_1_loss: 0.3236 - output_2_loss: 37.1589 - output_1_mean_absolute_error: 0.4926 - output_2_accuracy: 0.0688\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],  # 参数loss和metrics的结构必须与call()返回的内容完全匹配\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},  # 输入数据的结构必须与call()方法的输入完全匹配\n",
    "          [priority_data, department_data],  # 目标数据的结构必须与call()方法返回的内容完全匹配\n",
    "          epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924b24a-bef3-420e-b9d5-1c61a582ff28",
   "metadata": {},
   "source": [
    "### Model子类可以做什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589b206-bc93-4e29-8b63-6605a2bbec38",
   "metadata": {},
   "source": [
    "模型子类化是最灵活的模型构建方法。可以构建无法表示为层的**有向无环图的模型**。比如：call()方法在for循环中使用层，甚至递归调用这些层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6348f3c-c602-41d4-9057-8a143ad1798b",
   "metadata": {},
   "source": [
    "### 注意：Model子类不能做什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908194a4-9546-4aa7-81e5-1af28676ab85",
   "metadata": {},
   "source": [
    "对于子类化模型，需要负责更多的模型逻辑，**犯错的可能性会更大**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce24bb-5407-429d-a2b5-aeb973669cdb",
   "metadata": {},
   "source": [
    "#### 函数式模型和子类化模型本质上的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0fceb0-4fb0-44b3-96a9-22e3971ff9b8",
   "metadata": {},
   "source": [
    "- 函数式模型是一种数据结构 ———— 它是由层构成的图，可以查看、检查和修改它。\n",
    "- 子类化模型是一段字节码 ———— 它是带有call()方法的Python类，其中包含原始代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f232069-f139-4d6a-a5c2-0c5afea2b56b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 混合使用不同的组件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c91db-3da1-49b8-b872-fdf9a315b1f7",
   "metadata": {},
   "source": [
    "### 创建一个包含子类化模型的函数式模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5a3e3b-db36-442e-86f4-5e9259c99a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(3, ))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4968c3a-c77c-4997-8b68-60178d1adf9c",
   "metadata": {},
   "source": [
    "### 创建一个包含函数式模型的子类化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a592b62-9ebb-44b1-bb9e-1c3185fa9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64, ))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcde98-9a45-43f5-a633-b54d3b742bcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 使用内置的训练循环和评估循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773746f-5628-4626-b484-e6dce472ba6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 标准工作流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd20ef-1033-409d-836e-3e121312763a",
   "metadata": {},
   "source": [
    "1. **compile()：编译模型**\n",
    "2. **fit()：训练模型**\n",
    "3. **evaluate()：评估模型**\n",
    "4. **predict()：预测推理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51a24d79-fea6-4ac3-b5fb-0ae772deb847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2951 - accuracy: 0.9127 - val_loss: 0.1445 - val_accuracy: 0.9587\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1669 - accuracy: 0.9533 - val_loss: 0.1192 - val_accuracy: 0.9675\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1386 - accuracy: 0.9619 - val_loss: 0.1186 - val_accuracy: 0.9681\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9710\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 创建模型\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28, ))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# 加载数据，保留一部分数据用于验证\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "model = get_mnist_model()\n",
    "# 编译模型，complie()，指定模型的优化器、需要最小化的损失函数和需要监控的指标\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "# 使用fit()训练模型，可以选择提供验证数据来监控模型在前所未见的数据上的性能\n",
    "model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs=3, \n",
    "          validation_data=(val_images, val_labels))\n",
    "# 使用evaluate()计算模型在新数据上的损失和指标\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "# 使用predict()计算模型在新数据上的分类概率\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d191494-2bfd-4558-a6de-1d2eed7bd8f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 编写自定义指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107e5b7-de5d-44da-81a3-9b60d2739d54",
   "metadata": {},
   "source": [
    "指标是衡量模型性能的关键，尤其是衡量模型在训练数据上的性能与在测试数据上的性能之间的差异。<p>\n",
    "常用的分类指标和回归指标内置于**keras.metrics**模块中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235fa6e-8b63-4d0f-b7d5-4971ef9a521a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 如何编写自定义指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a17024-0bbf-43a5-9af0-3dad61cb4dd0",
   "metadata": {},
   "source": [
    "Keras指标是keras.metrics.Metrics类的子类。与层相同的是：指标具有一个存储在TensorFlow变量中的内部状态。与层不同的是，这些变量无法通过反向传播进行更新，必须编写状态更新逻辑。这一逻辑由`update_state()`方法实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea2039-a1bb-4dd9-81ea-d00809f06604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 编写自定义指标：用于衡量均方根误差(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac05407-afc2-4611-b5cd-2d878fbaf74a",
   "metadata": {},
   "source": [
    "#### 通过将Metric类子类化来实现自定义指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e575340-d174-4521-85ba-3f447f8c3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 将Metric类子类化\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    # 在构造函数中定义状态变量。与层一样，可以访问add_weight()方法\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    # 为了匹配MNIST模型，需要分类预测值与整数标签\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # 在update_state()中实现状态更新逻辑。y_true参数是一个数据批量对应的目标(或标签)，y_pred则表示相应的模型预测值。\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    # 使用result()方法返回指标的当前值\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    # 提供一个重置指标状态的方法\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58095911-1248-4a69-8701-8fb1865c191d",
   "metadata": {},
   "source": [
    "#### 测试自定义的RMSE指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a14d336c-fe10-4a43-af90-bd02a849cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2953 - accuracy: 0.9122 - rmse: 7.1818 - val_loss: 0.1713 - val_accuracy: 0.9507 - val_rmse: 7.3600\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1669 - accuracy: 0.9530 - rmse: 7.3544 - val_loss: 0.1189 - val_accuracy: 0.9673 - val_rmse: 7.4021\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1380 - accuracy: 0.9627 - rmse: 7.3885 - val_loss: 0.1089 - val_accuracy: 0.9716 - val_rmse: 7.4223\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9739 - rmse: 7.4346\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3e58d-e554-4506-8102-48be1188b6f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 使用回调函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2e996-5643-452e-8a20-033a6aaae720",
   "metadata": {},
   "source": [
    "回调函数是一个对象，它在调用`fit()`时被传入模型，并在训练过程中的不同时间点被模型调用。回调函数可以访问关于模型状态与模型性能的所有可用数据，还可以采用以下行动：\n",
    "- 中断训练\n",
    "- 保存模型\n",
    "- 加载一组不同的权重或者改变模型的状态 <p>\n",
    "\n",
    "**回调函数的一些用法示例如下：**\n",
    "- **模型检查点**(model checkpointing)：在训练过程中的不同时间点保存模型的当前状态。\n",
    "- **提前终止**(early stopping)：如果验证损失不再改善，则中断训练。\n",
    "- **在训练过程中动态调节某些参数值**：比如调节优化器的学习率。\n",
    "- **在训练过程中记录训练指标和验证指标，或者将模型学到的表示可视化(这些表示在不断更新)**：`fit()`进度条实际上就是一个回调函数。 <p>\n",
    "\n",
    "keras.callbacks模块包含许多内置的回调函数，下面列出一些：\n",
    "- `keras.callbacks.ModelCheckpoint`\n",
    "- `keras.callbacks.EarlyStopping`\n",
    "- `keras.callbacks.LearningRateScheduler`\n",
    "- `keras.callbacks.ReduceLROnPlateau`\n",
    "- `keras.callbacks.CSVLogger`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e037ec6-0ebd-4cec-80d7-7a04296bd0e1",
   "metadata": {},
   "source": [
    "### 回调函数EarlyStopping和ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893130e1-f454-4483-b10b-2986ec76c501",
   "metadata": {},
   "source": [
    "如果监控的目标指标在设定的轮数内不再改善，那么可以用EarlyStopping回调函数中断训练。这个回调函数通常与ModelCheckpoint结合使用，后者可以在训练过程中不断保存模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120a297-63d3-4183-8b8d-0030e82a98df",
   "metadata": {},
   "source": [
    "#### 在fit()方法中使用callbacks参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec734241-0af9-48f4-9804-35754960f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2988 - accuracy: 0.9112 - val_loss: 0.1647 - val_accuracy: 0.9534\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1672 - accuracy: 0.9538 - val_loss: 0.1268 - val_accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1383 - accuracy: 0.9632 - val_loss: 0.1105 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1282 - accuracy: 0.9670 - val_loss: 0.1147 - val_accuracy: 0.9712\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1185 - accuracy: 0.9701 - val_loss: 0.1088 - val_accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1121 - accuracy: 0.9728 - val_loss: 0.1033 - val_accuracy: 0.9773\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1031 - accuracy: 0.9753 - val_loss: 0.1253 - val_accuracy: 0.9721\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1048 - accuracy: 0.9763 - val_loss: 0.1103 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa01a0aefb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过fit()的callbacks参数将回调函数传入模型中，该参数接收一个回调函数列表，可以传入任意数量的回调函数\n",
    "callbacks_list = [\n",
    "    # 如果不改善，则中断训练\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # 监控模型的验证精度\n",
    "        monitor=\"val_accuracy\",\n",
    "        # 如果精度在两轮内都不再改善，则中断训练\n",
    "        patience=2\n",
    "    ),\n",
    "    # 在每轮过后保存当前权重\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # 模型文件的保存路径\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        # 这两个参数的含义是，只有当val_loss改善时，才会覆盖模型文件\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs=10, \n",
    "          callbacks=callbacks_list, \n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c5595-7f96-498d-8f84-01176402ae5d",
   "metadata": {},
   "source": [
    "#### 加载已保存的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3b7b68a-18a6-497b-aaf5-38e1774f0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201645d-6141-4a92-a0a0-2d2920999607",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 编写自定义回调函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7ffe3-2377-48f9-8848-9518dd449d8e",
   "metadata": {},
   "source": [
    "自定义回调函数的实现方式是将`keras.callbacks.Callback`类子类化。可以实现下列方法，在训练过程中的不同时间点被调用。<p>\n",
    "```\n",
    "on_epoch_begin(epoch, logs)  # 在每轮开始时被调用\n",
    "on_epoch_end(epoch, logs)  # 在每轮结束时被调用\n",
    "on_batch_begin(batch, logs)  # 在处理每个批量之前被调用\n",
    "on_batch_end(batch, logs)  # 在处理每个批量之后被调用\n",
    "on_train_begin(logs)  # 在训练开始时被调用\n",
    "on_train_end(logs)  # 在训练结束时被调用\n",
    "```\n",
    "<p>\n",
    "\n",
    "上述方法都用到了参数 **logs**。这个参数是一个字典，它包含前一个批量、前一个轮次或前一次训练的信息，比如：训练指标和验证指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fed477-cfd5-40dd-933e-cc04028008f5",
   "metadata": {},
   "source": [
    "### 通过对Callback类子类化来创建自定义回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9fe737f-0550-4aad-997a-77302189ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练过程中保存每个批量损失值组成的列表，还在每轮结束时保存这些损失值组成的图\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, epoch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses, label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a5dc291-4efd-4f29-a2e7-c682cc269531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2957 - accuracy: 0.9121 - val_loss: 0.1459 - val_accuracy: 0.9594\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1668 - accuracy: 0.9528 - val_loss: 0.1286 - val_accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1398 - accuracy: 0.9630 - val_loss: 0.1163 - val_accuracy: 0.9694\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.1185 - val_accuracy: 0.9714\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1203 - accuracy: 0.9702 - val_loss: 0.1058 - val_accuracy: 0.9749\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1075 - accuracy: 0.9735 - val_loss: 0.1140 - val_accuracy: 0.9753\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1041 - accuracy: 0.9749 - val_loss: 0.1122 - val_accuracy: 0.9761\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1013 - accuracy: 0.9769 - val_loss: 0.1177 - val_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9779 - val_loss: 0.1110 - val_accuracy: 0.9803\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0948 - accuracy: 0.9788 - val_loss: 0.1202 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa00864ac50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks=[LossHistory()], validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998ae24-f32f-45c7-b681-1b4b5751933a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 利用TensorBoard进行监控和可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb6690-690e-42a9-9b33-97694b155df6",
   "metadata": {},
   "source": [
    "TensorBoard是一个基于浏览器的应用程序，可以在本地运行。它是在训练过程中监控模型的最佳方式。利用TensorBoard，可以做以下工作：\n",
    "- 在训练过程中以可视化方式监控指标；\n",
    "- 将模型架构可视化；\n",
    "- 将激活函数和梯度的直方图可视化；\n",
    "- 以三维形式研究嵌入 <p>\n",
    "\n",
    "要将TensorBoard与Keras模型和`fit()`方法一起使用，最简单的方式就是使用`keras.callbacks.TensorBoard`回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb63aa01-6fe6-4cb8-8d80-25b1fe5ecd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2941 - accuracy: 0.9135 - val_loss: 0.1457 - val_accuracy: 0.9595\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1663 - accuracy: 0.9532 - val_loss: 0.1260 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1419 - accuracy: 0.9622 - val_loss: 0.1172 - val_accuracy: 0.9676\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1290 - accuracy: 0.9669 - val_loss: 0.1179 - val_accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1197 - accuracy: 0.9698 - val_loss: 0.1068 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1100 - accuracy: 0.9730 - val_loss: 0.1118 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9755 - val_loss: 0.1111 - val_accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1017 - accuracy: 0.9766 - val_loss: 0.1116 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1000 - accuracy: 0.9777 - val_loss: 0.1206 - val_accuracy: 0.9766\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0936 - accuracy: 0.9778 - val_loss: 0.1154 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa01af8d4b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./chapter07_tensorboard_log_dir\"\n",
    ")\n",
    "model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs=10, \n",
    "          validation_data=(val_images, val_labels), \n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bd7ac47-dd1e-404c-8a86-1216989a27eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with -4)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./chapter07_tensorboard_log_dir --verbosity=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e08ccf-5c13-401b-9e8c-4d53b2fadcbd",
   "metadata": {},
   "source": [
    "# 编写自定义的训练循环和评估循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe73942-8f24-4df0-8a5f-6dc2fb036a66",
   "metadata": {},
   "source": [
    "`fit()`工作流程在易用性和灵活性之间实现了很好的平衡。但它无法实现深度学习研究人员想做的一切事情。<p>\n",
    "**内置的fit()缺点：** 内置`fit()`工作流程只针对**监督学习**。监督学习是指：已知与输入数据相关联的**目标**，将损失计算为这些目标和模型预测值的函数。但**非监督学习**，如**生成式学习**、**自监督学习**和**强化学习**。<p>\n",
    "编写自定义的训练逻辑，典型的训练循环包含以下内容：\n",
    "1. 在梯度带中运行前向传播（计算模型输出），得到当前数据批量的损失值；\n",
    "2. 检索损失相当于模型权重的梯度；\n",
    "3. 更新模型权重，以降低当前数据批量的损失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e82787-ad91-46c8-b16f-e4b44cbd6180",
   "metadata": {},
   "source": [
    "## 训练与推断"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50ac26-e827-4843-b007-472487057aa8",
   "metadata": {},
   "source": [
    "在典型训练循环中，步骤1（前向传播）是通过`predicitions = model(inputs)`完成的，步骤2（检索梯度带计算的梯度）是通过`gradients = tape.gradient(loss, model.weights)`完成的。在一般情况下，**还有两个细节需要考虑**：\n",
    "1. 某些Keras层（如：Dropout层），在训练过程和推断过程中具有不同的行为。这些层的call()方法中有一个名为`training`的bool参数。调用`dropout(inputs, training=True)`将舍弃一些激活单元，而调用`dropout(inputs, training=False)`则不会舍弃。在前向传播中调用Keras模型时，**一定要记得传入`training=True`**。即前向传播应该变成`predictions = model(inputs, training=True)`。\n",
    "2. 检索模型权重的梯度时，不应该使用`tape.gradients(loss, model.weights)`，而应使用tape.gradients(loss, model.trainable_weights)。层和模型具有以下两种权重：\n",
    "    - **可训练权重（trainable weight）**：通过反向传播对这些权重进行更新，以便将模型损失最小化。比如：Dense层的核和偏置就是可训练权重。\n",
    "    - **不可训练权重（non-trainable weight）**：在前向传播过程中，这些权重所在的层对它们进行更新。如果像自定义一层，用于记录该层处理了多少个批量，那么这一信息需要存储在一个不可训练权重中。每处理一个批量，该层将计数器加1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326a7e3-d1c9-4425-b4af-00b9297bbece",
   "metadata": {},
   "source": [
    "### 监督学习的训练步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd84f6-004c-4ea3-ba48-75ff2d1d6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradients(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(model.trainable_weights, gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83236faf-98c8-4da4-b4f7-829b704235c4",
   "metadata": {},
   "source": [
    "## 指标的低阶用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce71972-0355-4989-a415-7e7119a33c41",
   "metadata": {},
   "source": [
    "在低阶训练循环中，可能会用到Keras指标（无论是自定义还是内置）。指标API：只需要对每一个目标和预测值组成的批量调用`update_state(y_true, y_pred)`，然后使用`result()`查询当前指标值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f0e48a1-8d89-4f2d-8451-8d7e25bae5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47a07eb7-78a7-4ba1-a775-90e892432862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "# 追踪某个标量值（如：模型损失）的均值\n",
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0c41e-9dd7-49b7-91b2-5a7814ec15d2",
   "metadata": {},
   "source": [
    "想要重置当前结果（在一轮训练开始或评估开始时），**记得使用`metric.reset_state()`** 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd5ee4-cfe5-45a6-84a3-9b24a8b4a6fc",
   "metadata": {},
   "source": [
    "## 完整的训练循环和评估循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04661d-d169-438c-9d9c-018fdf55e90a",
   "metadata": {},
   "source": [
    "将前向传播、反向传播和指标跟踪组合成一个类似于fit()的训练步骤函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601e91b-0c44-4194-bbea-0f0e7601ff8b",
   "metadata": {},
   "source": [
    "### 逐步编写训练循环：训练步骤函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ab88cdf-d416-466c-a313-549c13c1d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "# 准备损失函数\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "# 准备优化器\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "# 准备需要监控的指标列表\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "# 准备Mean指标跟踪器来跟踪损失均值\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 运行前向传播\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "        # 运行反向传播\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    # 跟踪指标\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    # 跟踪损失均值\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    # 返回当前的指标和损失值\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dfecda-afa4-49dd-8a00-3713ce7aef4a",
   "metadata": {},
   "source": [
    "### 逐步编写训练循环：重置指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b153b3e-132e-4608-b1f6-b07dbd5bbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f389b21-d8d1-4ba1-85fc-286b00fddbe0",
   "metadata": {},
   "source": [
    "### 逐步编写训练循环：循环本身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93434be9-e229-4a88-a682-225683422bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch: 0\n",
      "...sparse_categorical_accuracy: 0.9153\n",
      "...loss: 0.2880\n",
      "Results at the end of epoch: 1\n",
      "...sparse_categorical_accuracy: 0.9540\n",
      "...loss: 0.1657\n",
      "Results at the end of epoch: 2\n",
      "...sparse_categorical_accuracy: 0.9624\n",
      "...loss: 0.1413\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 在每轮训练开始时，重置指标\n",
    "    reset_metrics()\n",
    "    # 开始本轮训练\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch: {epoch}\")\n",
    "    # 打印评估指标\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4d326-5303-4344-a6b2-259b6d87b3c7",
   "metadata": {},
   "source": [
    "### 逐步编写评估循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a9681-7643-4e30-b934-69ae673a3958",
   "metadata": {},
   "source": [
    "评估循环：一个简单的for循环，重复调用`test_step()`函数。`test_step()`函数只是`train_step()`逻辑的子集。它省略了处理更新模型权重的代码，即所有涉及GradientTape和优化器代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd7781ea-6f4f-4219-b58a-5bb1e60f6c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9663\n",
      "...val_loss: 0.1367\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f451ca-8275-4033-98c0-fad965ece2db",
   "metadata": {},
   "source": [
    "## 利用tf.function加快运行速度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848672e-94df-4807-aabf-3be5c57c45a5",
   "metadata": {},
   "source": [
    "将TensorFlow代码编译成**计算图**，对改计算图进行全局优化，这是逐行解释代码所无法实现的。**语法：** 对于需要在执行前编译的函数，只需添加`@tf.function`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e059e78c-0185-41e9-b701-ad03c4740f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9663\n",
      "...val_loss: 0.1367\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d173b02-8333-4667-b8a6-eaacb5c66503",
   "metadata": {},
   "source": [
    "## 在fit()中使用自定义训练循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e72bd-0c92-4614-b6c7-c3441c2db63a",
   "metadata": {},
   "source": [
    "在前面我们从头开始编写了自定义训练循环。这样做具有最大的灵活性，但需要编写大量代码，同时无法利用fit()提供的许多方便的特性，比如：回调函数或对分布式训练的支持。<p>\n",
    "如果像自定以训练算法，但仍想使用Keras内置训练逻辑的强大功能。可以编写自定义的训练步骤函数，然后让框架完成其余工作。<p>\n",
    "可以通过覆盖Model类的`train_step()`方法来实现这一点。它是`fit()`对每批数据调用的函数。然后，可以像平常一样调用`fit()`，将在后台运行自定义的学习算法。<p>\n",
    "实现一个简单的例子：\n",
    "- 创建一个新类，它是`keras.Model`的子类。\n",
    "- 覆盖`train_step(self, data)`方法。\n",
    "- 实现`metrics`属性，用于跟踪模型的Metric实例。这样模型可以在每轮开始时和调用`evaluate()`时对模型指标自动调用`reset_state()`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1ac55-75f0-43b3-80b0-a5197d633c58",
   "metadata": {},
   "source": [
    "### 实现自定义训练步骤，并与fit()结合使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81106714-034a-4004-ad01-f64152fbf4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "            gradients = tape.gradient(loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94abfc-808e-4f75-a5ff-a70886fb6ef3",
   "metadata": {},
   "source": [
    "将自定义模型实例化，编译模型（只传入优化器，因为损失函数已在模型之外定义），并像平常一样使用fit()训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f62ad6f4-80e6-4721-94ed-01b92359d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2948\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1658\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa03bbcd630>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28, ))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29eb3a8-c2d2-4136-ae78-947ce7b6d6a1",
   "metadata": {},
   "source": [
    "### 通过compile()配置损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d6dc2-d36d-46e2-8492-0c6d5accf125",
   "metadata": {},
   "source": [
    "在调用`compile()`之后，可以访问以下内容：\n",
    "- `self.compiled_loss`：传入compile()的损失函数。\n",
    "- `self.compiled_metrics`：传入的指标列表的包装器，它允许调用`self.compiled_metrics.update_state()`来一次性更新所有指标。\n",
    "- `self.metrics`：传入compile()的指标列表。它还包括一个跟踪损失的指标，类似于之前用loss_tracking_metric手动实现的例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f10c6b45-0366-4039-98e8-f243d7bc99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "            gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "222e5091-9a37-4d21-a26d-af3bbf0a2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2920 - sparse_categorical_accuracy: 0.9140\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1658 - sparse_categorical_accuracy: 0.9530\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa03c102b30>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28, ))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(), \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2b6a2-100b-426b-b354-a26c53f89d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hjw",
   "language": "python",
   "name": "hjw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
